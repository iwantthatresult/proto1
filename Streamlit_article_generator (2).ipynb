{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMy6YHE86dHD"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "subprocess.run([\"pip\", \"install\", \"openai\"])\n",
        "subprocess.run([\"pip\", \"install\", \"streamlit\"])\n",
        "subprocess.run([\"pip\", \"install\", \"fitz\"])\n",
        "subprocess.run([\"sudo\", \"apt\", \"install\", \"texlive\"])\n",
        "subprocess.run([\"pip\", \"install\", \"python-docx\"])\n",
        "subprocess.run([\"pip\", \"install\", \"streamlit\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z705mTo4TpJB"
      },
      "source": [
        "# Article Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL8J3DR903vi"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import openai\n",
        "import pandas as pd\n",
        "import requests\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import subprocess\n",
        "import requests\n",
        "import tempfile\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import subprocess\n",
        "import io\n",
        "import zipfile\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def get_terms(string):\n",
        "    terms = []\n",
        "    start_index = 0\n",
        "    end_index = string.find('\\n', start_index)\n",
        "    while end_index != -1:\n",
        "        term = string[start_index:end_index]\n",
        "        if term.strip() != \"\":\n",
        "            terms.append(term)\n",
        "        start_index = end_index + 1\n",
        "        end_index = string.find('\\n', start_index)\n",
        "    term = string[start_index:]\n",
        "    if term.strip() != \"\":\n",
        "        terms.append(term)\n",
        "    return terms\n",
        "\n",
        "\n",
        "\n",
        "def create_content(input):\n",
        "  # Generate the article content using the GPT-3 API\n",
        "  image_prompt = openai.Completion.create(model=\"text-davinci-003\",\n",
        "  prompt=\"write 4 image generation prompt starting the prompt with 'HQ, 4k,fine details cinematic intricate scenery, artistic, real photography of' of 15 words each to generate images using generative AI for an article about \"+input,\n",
        "  max_tokens=4000,\n",
        "  temperature=0.9,top_p=1,n=1,)\n",
        "  image_content = image_prompt.choices[0].text\n",
        "  image_prompts=get_terms(image_content)\n",
        "  image_urls = []\n",
        "  # Get the URL of the generated image\n",
        "  for i in range(0,len(image_prompts)):\n",
        "    # Generate an image using the DALL-E API\n",
        "    response = openai.Image.create(prompt=image_prompts[i],n=1,size=\"1024x1024\")\n",
        "    image_urls.append(response.data[0].url)\n",
        "  # Generate an image using the DALL-E API\n",
        "  response = openai.Image.create(prompt='realistic photography of '+input,n=4,size=\"1024x1024\")\n",
        "  image_urls.append(response.data[0].url)\n",
        "  image_urls.append(response.data[1].url)\n",
        "  image_urls.append(response.data[2].url)\n",
        "  image_urls.append(response.data[3].url)\n",
        "  pr=\"write with an adequate semantical structure and information structure to make it SEO compliant an article about \"+str(input)+\" with 4 different parts containing 400 words each and dealing with different aspects about \"+str(input)\n",
        "  # Generate the article content using the GPT-3 API\n",
        "  completions = openai.Completion.create(model=\"text-davinci-003\",prompt=pr,\n",
        "  max_tokens=4000,temperature=0.9,top_p=1,n=1,)\n",
        "  # Get the generated article content\n",
        "  article_content = completions.choices[0].text\n",
        "  # Create a DataFrame with the generated data\n",
        "  data = {'image_url': image_urls, 'article_content': article_content,'image prompt':image_content}\n",
        "  # Print the DataFrame\n",
        "  return data\n",
        "\n",
        "\n",
        "def create_docx(text, images_url, watermark_image_url):\n",
        "    # Create a new Word document\n",
        "    document = Document()\n",
        "\n",
        "    # Add the text to the document\n",
        "    document.add_paragraph(text)\n",
        "\n",
        "    # Add the images to the document\n",
        "    for url in images_url:\n",
        "        response = requests.get(url)\n",
        "        img = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
        "        _, img_encoded = cv2.imencode('.jpg', img)\n",
        "        # Create a file-like object from the encoded image data\n",
        "        img = BytesIO(img_encoded)\n",
        "        document.add_picture(img, width=Inches(6))\n",
        "\n",
        "    # Add the watermark image to the top right corner of each page\n",
        "    response = requests.get(watermark_image_url)\n",
        "    img = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
        "    _, img_encoded = cv2.imencode('.jpg', img)\n",
        "    # Create a file-like object from the encoded image data\n",
        "    img = BytesIO(img_encoded)\n",
        "    header = document.sections[0].header\n",
        "    paragraph = header.paragraphs[0]\n",
        "    logo_run = paragraph.add_run()\n",
        "    logo_run.add_picture(img, width=Inches(1))\n",
        "    text_run = paragraph.add_run()\n",
        "    text_run.text = '\\t' + \"This was made by creAIte\" # For center align of text\n",
        "    text_run.style = \"Heading 2 Char\"\n",
        "\n",
        "    # Save the document\n",
        "    document.save(input1+'.docx')\n",
        "    subprocess.run(['pandoc' ,'-s' ,input1+'.docx','-o',input1+'.pdf'])\n",
        "\n",
        "def create_docx(text, images_url, watermark_image_url):\n",
        "    # Create a new Word document\n",
        "    document = Document()\n",
        "\n",
        "    # Add the text to the document\n",
        "    document.add_paragraph(text)\n",
        "\n",
        "    # Add the images to the document\n",
        "    for url in images_url:\n",
        "        response = requests.get(url)\n",
        "        img = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
        "        _, img_encoded = cv2.imencode('.jpg', img)\n",
        "        # Create a file-like object from the encoded image data\n",
        "        img = BytesIO(img_encoded)\n",
        "        document.add_picture(img, width=Inches(6))\n",
        "\n",
        "    # Add the watermark image to the top right corner of each page\n",
        "    response = requests.get(watermark_image_url)\n",
        "    img = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
        "    _, img_encoded = cv2.imencode('.jpg', img)\n",
        "    # Create a file-like object from the encoded image data\n",
        "    img = BytesIO(img_encoded)\n",
        "    header = document.sections[0].header\n",
        "    paragraph = header.paragraphs[0]\n",
        "    logo_run = paragraph.add_run()\n",
        "    logo_run.add_picture(img, width=Inches(1))\n",
        "    text_run = paragraph.add_run()\n",
        "    text_run.text = '\\t' + \"This was made by creAIte\" # For center align of text\n",
        "    text_run.style = \"Heading 2 Char\"\n",
        "\n",
        "    # Save the document to a temporary file\n",
        "    with tempfile.TemporaryDirectory() as tempdir:\n",
        "        temp_file = tempdir + '/temp.docx'\n",
        "        document.save(temp_file)\n",
        "        subprocess.run(['pandoc' ,'-s' ,temp_file,'-o',input1+'.pdf'])\n",
        "\n",
        "def download_images(urls, zip_name):\n",
        "  # create a zip file object\n",
        "  zip_buffer = io.BytesIO()\n",
        "  zip_file = zipfile.ZipFile(zip_buffer, \"w\", zipfile.ZIP_DEFLATED)\n",
        "\n",
        "  # download each image and add it to the zip file\n",
        "  for url in urls:\n",
        "    response = requests.get(url)\n",
        "    image_data = response.content\n",
        "\n",
        "    # create a unique file name for the image\n",
        "    file_name = url.split(\"/\")[-1] + \".png\"\n",
        "\n",
        "    # add the image to the zip file\n",
        "    zip_file.writestr(file_name, image_data)\n",
        "\n",
        "  # close the zip file\n",
        "  zip_file.close()\n",
        "\n",
        "  # write the zip file to disk\n",
        "  with open(zip_name, \"wb\") as f:\n",
        "    f.write(zip_buffer.getvalue())\n",
        "\n",
        "def imgshow(url,imgnum):\n",
        "  response = requests.get(url)\n",
        "  img = Image.open(BytesIO(response.content))\n",
        "  imgnum=st.image(img, width=200)\n",
        "\n",
        "\n",
        "def file_downloader(file_path, file_name):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_data = f.read()\n",
        "    with open(file_name, \"wb\") as f:\n",
        "        f.write(file_data)\n",
        "    return file_name\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "S1WLGsqNM1pQ",
        "outputId": "9d20d8ed-3fff-4fa8-826c-9b788db0ad31"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-afd0313f128e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Display some text\n",
        "header=st.header('Article Generator')\n",
        "st.write('This streamlit app was developped by CreAIte, the goal is to prototype what are the possibilities for content creation that generative AI bring to the table. Please feel free to use it and give us some feedback ! Please have fun creating with us !')\n",
        "\n",
        "\n",
        "result=st.button('Generate your article')\n",
        "\n",
        "input1=st.text_input('What is the subject of the article ? ')\n",
        "input2=st.text_input('What is the name of the zip file you want for download ')\n",
        "input3=st.text_input('What is your OPEN AI API Key ?')\n",
        "\n",
        "\n",
        "\n",
        "if result==True:\n",
        "  # Set the API key\n",
        "  openai.api_key = input3\n",
        "  data=create_content(input1)\n",
        "  urls= data['image_url']\n",
        "  create_docx(data['article_content'],data['image_url'],data['image_url'][0])\n",
        "  zip_name = str(input2)+\".zip\"\n",
        "  download_images(data[\"image_url\"], zip_name)\n",
        "  response1 = requests.get(urls[0])\n",
        "  response2 = requests.get(urls[1])\n",
        "  response3 = requests.get(urls[2])\n",
        "  response4 = requests.get(urls[3])\n",
        "  img1 = Image.open(BytesIO(response1.content))  \n",
        "  img2 = Image.open(BytesIO(response2.content))  \n",
        "  img3 = Image.open(BytesIO(response3.content))  \n",
        "  img4 = Image.open(BytesIO(response4.content))\n",
        "  imgshow1=st.image(img1, width=200)\n",
        "  imgshow2=st.image(img2, width=200)\n",
        "  imgshow3=st.image(img3, width=200)\n",
        "  imgshow4=st.image(img4, width=200)\n",
        "  \n",
        "  st.write(\"List of all files in the '/content/' directory:\")\n",
        "  for root, dirs, files in os.walk(\"/content/\"):\n",
        "    for filename in files:\n",
        "        st.write(os.path.join(root, filename))\n",
        "\n",
        "\n",
        "\n",
        "  with open(zip_name, \"rb\") as file:\n",
        "    btn = st.download_button(label=\"Download image zip file\",data=file,file_name=input2+'.zip',mime=\"application/octet-stream\")\n",
        "  with open(input1+\".docx\", \"rb\") as file:\n",
        "    btn = st.download_button(label=\"Download docx file\",data=file,file_name=input1+'.docx',mime=\"application/octet-stream\")\n",
        "  with open(input1+\".pdf\", \"rb\") as file:\n",
        "    btn = st.download_button(label=\"Download pdf file\",data=file,file_name=input1+'.pdf',mime=\"application/octet-stream\")\n",
        "  for url in urls:\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    st.image(img, width=200)\n",
        "\n",
        "cwd=os.getcwd()\n",
        "\n",
        "#if st.button(\"Download File.docx\"):\n",
        "#    file_path = cwd+ \"/\"+input1+\".docx\"\n",
        "#    file_name = file_downloader(file_path, input1+\".docx\")\n",
        " #   st.success(f\"{file_name} downloaded successfully\")\n",
        "\n",
        "#if st.button(\"Download File.pdf\"):\n",
        "#    file_path = cwd+ \"/\"+input1+\".pdf\"\n",
        " #   file_name = file_downloader(file_path, input1+\".pdf\")\n",
        "  #  st.success(f\"{file_name} downloaded successfully\")"
      ]
    }
  ]
}